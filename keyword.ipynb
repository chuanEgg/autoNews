{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzM8Fup0V8Ko",
        "outputId": "4674f3f0-5157-4395-8d25-9337b346100f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ckiptagger\n",
            "  Downloading ckiptagger-0.2.1-py3-none-any.whl (34 kB)\n",
            "Installing collected packages: ckiptagger\n",
            "Successfully installed ckiptagger-0.2.1\n"
          ]
        }
      ],
      "source": [
        "!pip install -U ckiptagger"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from ckiptagger import data_utils, construct_dictionary, WS, POS, NER\n",
        "data_utils.download_data_gdown(\"./\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BVXCz56nWL_i",
        "outputId": "a144e7d6-7b77-4a39-a376-36f65a03a5d0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1efHsY16pxK0lBD2gYCgCTnv1Swstq771\n",
            "To: /content/data.zip\n",
            "100%|██████████| 1.88G/1.88G [00:39<00:00, 47.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AITHE5miKhjP",
        "outputId": "00b8ad1e-34a8-4333-924c-7c642c0542e5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"data.txt\", \"r\", encoding = \"utf-8\") as f:\n",
        "    data = f.read()\n",
        "\n",
        "print(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6JmcylkgK9jJ",
        "outputId": "1077e5a4-813a-4fd2-c1a6-90b05329c67a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "拜登和習近平將在舊金山會面，討論如何避免核戰爭、人工智慧殺人機器和台灣問題。這是一場歷史性的峰會，因為這是兩位領導人第一次面對面交流，而不是通過翻譯或Zoom。拜登希望能夠說服習近平，中國不應該干涉美國的內政，比如支持俄羅斯、哈馬斯和菲律賓。習近平則希望能夠說服拜登，美國不應該干涉中國的內政，比如支持台灣、維吾爾和香港。兩位領導人都有自己的底線，但也有共同的利益，比如維持貿易、防止疫情和打擊芬太尼。這次會談的成果將取決於兩國是否能夠重啟軍事交流，讓兩軍能夠直接溝通，而不是用飛機艦艇互相威脅。這是一個艱難的任務，但也是一個必要的步驟，因為如果不這樣做，世界可能會變成一個更危險的地方。當然，這也可能是一個無聊的會談，因為兩國在很多問題上都沒有太多妥協空間，而且會談後也不會發布聯合公報。所以，我們只能祈禱，這次會談不會變成一場空洞的禮節性活動，而是一場真正的對話，能夠為中美關係帶來一些改善。不過，我們也不要抱太大的期望，因為這是拜登和習近平，而不是奧巴馬和達賴喇嘛。\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ws = WS(\"./data\")\n",
        "pos = POS(\"./data\")\n",
        "ner = NER(\"./data\")"
      ],
      "metadata": {
        "id": "i-SXKhNLW2EU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86fe3ca4-a186-4747-d6ba-bef573422a75"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ckiptagger/model_ws.py:106: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
            "/usr/local/lib/python3.10/dist-packages/ckiptagger/model_pos.py:56: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n",
            "/usr/local/lib/python3.10/dist-packages/ckiptagger/model_ner.py:57: UserWarning: `tf.nn.rnn_cell.LSTMCell` is deprecated and will be removed in a future version. This class is equivalent as `tf.keras.layers.LSTMCell`, and will be replaced by that in Tensorflow 2.0.\n",
            "  cell = tf.compat.v1.nn.rnn_cell.LSTMCell(hidden_d, name=name)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = []\n",
        "i = data\n",
        "line = []\n",
        "line.append(i)\n",
        "# print(line)\n",
        "seg_res = ws(line)\n",
        "pos_res = pos(seg_res)\n",
        "ner_res = ner(seg_res, pos_res)\n",
        "# print(ner_res)\n",
        "keywords = []\n",
        "skip = ['CARDINAL', 'DATE', 'TIME', 'MONEY', 'ORDINAL', 'QUANTITY', 'PERCENT']\n",
        "if len(ner_res) != 0:\n",
        "  for i in ner_res[0]:\n",
        "    # print(i[3])\n",
        "    if i[2] in skip: continue\n",
        "    keywords.append({'content': i[3],'type': i[2], 'head': i[0]})\n",
        "\n",
        "idx = 0\n",
        "for i in range(len(seg_res[0])):\n",
        "  # print(pos_res[0][i], seg_res[0][i])\n",
        "  if pos_res[0][i] == 'Na':\n",
        "    if i != 0 and pos_res[0][i-1] == 'Na': # merging noun as they are likely to be refering a single object\n",
        "      keywords[-1]['content'] += seg_res[0][i]\n",
        "    elif i >= 2 and pos_res[0][i-1] == 'DE' and pos_res[0][i-2] == 'VH': # to include adj+noun (ex. 無聊的會議)\n",
        "      keywords.append({'content': seg_res[0][i-2]+seg_res[0][i], 'type': 'VH+Na', \\\n",
        "                        'head': (idx-len(seg_res[0][i-1])-len(seg_res[0][i-2]))})\n",
        "    else:\n",
        "      keywords.append({'content': seg_res[0][i], 'type': 'Na', 'head': idx})\n",
        "  # if pos_res[0][i] == 'Nb' and seg_res[0][i] not in keywords:\n",
        "  #     keywords.append({'content': seg_res[0][i], 'type': 'Nb', 'head': idx})\n",
        "  idx += len(seg_res[0][i])\n",
        "\n",
        "idx = 0\n",
        "if len(keywords) == 0:\n",
        "  for i in range(len(seg_res[0])):\n",
        "    if 'V' in pos_res[0][i] and pos_res[0][i] != 'VH':\n",
        "      if i >= 2 and pos_res[0][i-1] == 'DE' and pos_res[0][i-2] == 'VH':\n",
        "        keywords.append({'content': seg_res[0][i-2]+seg_res[0][i], 'type': 'VH+V', \\\n",
        "                        'head': (idx-len(seg_res[0][i-1])-len(seg_res[0][i-2]))})\n",
        "      else:\n",
        "        keywords.append({'content': seg_res[0][i], 'type': 'V', 'head': idx})\n",
        "    idx += len(seg_res[0][i])\n",
        "\n",
        "print(keywords)\n",
        "# result.append(keywords)"
      ],
      "metadata": {
        "id": "nuqoRZrPLQ_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f923b8d9-726c-4f74-b769-6dcc05f8f1b8"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'content': '菲律賓', 'type': 'GPE', 'head': 117}, {'content': '拜登', 'type': 'PERSON', 'head': 80}, {'content': '美國', 'type': 'GPE', 'head': 99}, {'content': '美', 'type': 'GPE', 'head': 388}, {'content': '中國', 'type': 'GPE', 'head': 141}, {'content': '達賴喇嘛', 'type': 'PERSON', 'head': 431}, {'content': '習近平', 'type': 'PERSON', 'head': 420}, {'content': '美國', 'type': 'GPE', 'head': 134}, {'content': '哈馬斯', 'type': 'GPE', 'head': 113}, {'content': '香港', 'type': 'GPE', 'head': 158}, {'content': '拜登', 'type': 'PERSON', 'head': 0}, {'content': '台灣', 'type': 'GPE', 'head': 33}, {'content': '舊金山', 'type': 'GPE', 'head': 8}, {'content': '拜登', 'type': 'PERSON', 'head': 131}, {'content': '奧巴馬', 'type': 'PERSON', 'head': 427}, {'content': '中', 'type': 'GPE', 'head': 387}, {'content': '台灣', 'type': 'GPE', 'head': 151}, {'content': '中國', 'type': 'GPE', 'head': 92}, {'content': '俄羅斯', 'type': 'GPE', 'head': 109}, {'content': '維吾爾', 'type': 'GPE', 'head': 154}, {'content': '拜登', 'type': 'PERSON', 'head': 417}, {'content': 'Zoom', 'type': 'PERSON', 'head': 75}, {'content': '習近平將', 'type': 'PERSON', 'head': 3}, {'content': '習近平', 'type': 'PERSON', 'head': 121}, {'content': '核戰爭', 'type': 'Na', 'head': 20}, {'content': '人工智慧', 'type': 'Na', 'head': 24}, {'content': '機器', 'type': 'Na', 'head': 30}, {'content': '問題', 'type': 'Na', 'head': 35}, {'content': '歷史性', 'type': 'Na', 'head': 42}, {'content': '峰會', 'type': 'Na', 'head': 46}, {'content': '領導人', 'type': 'Na', 'head': 55}, {'content': '翻譯', 'type': 'Na', 'head': 72}, {'content': '內政', 'type': 'Na', 'head': 102}, {'content': '內政', 'type': 'Na', 'head': 144}, {'content': '領導人', 'type': 'Na', 'head': 163}, {'content': '底線', 'type': 'Na', 'head': 171}, {'content': '利益', 'type': 'Na', 'head': 180}, {'content': '貿易', 'type': 'Na', 'head': 187}, {'content': '疫情', 'type': 'Na', 'head': 192}, {'content': '芬太尼', 'type': 'Na', 'head': 197}, {'content': '成果', 'type': 'Na', 'head': 206}, {'content': '軍事', 'type': 'Na', 'head': 220}, {'content': '軍', 'type': 'Na', 'head': 227}, {'content': '飛機艦艇', 'type': 'Na', 'head': 239}, {'content': '艱難任務', 'type': 'VH+Na', 'head': 252}, {'content': '必要步驟', 'type': 'VH+Na', 'head': 263}, {'content': '危險地方', 'type': 'VH+Na', 'head': 288}, {'content': '問題', 'type': 'Na', 'head': 317}, {'content': '空間', 'type': 'Na', 'head': 327}, {'content': '空洞禮節性活動', 'type': 'VH+Na', 'head': 365}, {'content': '對話', 'type': 'Na', 'head': 381}, {'content': '關係', 'type': 'Na', 'head': 389}, {'content': '大期望', 'type': 'VH+Na', 'head': 408}, {'content': '喇嘛', 'type': 'Na', 'head': 433}]\n",
            "{'content': '美', 'type': 'GPE', 'head': 388} {'content': '關係', 'type': 'Na', 'head': 389}\n",
            "{'content': '達賴喇嘛', 'type': 'PERSON', 'head': 431} {'content': '喇嘛', 'type': 'Na', 'head': 433}\n",
            "{'content': '台灣', 'type': 'GPE', 'head': 33} {'content': '問題', 'type': 'Na', 'head': 35}\n",
            "{'content': '中', 'type': 'GPE', 'head': 387} {'content': '美', 'type': 'GPE', 'head': 388}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_delete = []\n",
        "for i in keywords:\n",
        "  for j in keywords:\n",
        "    if i[\"head\"] < j[\"head\"] and i[\"head\"] + len(i[\"content\"]) >= (j[\"head\"]+len(j[\"content\"])):\n",
        "      print(i, j)\n",
        "      to_delete.append(j)\n",
        "\n",
        "keywords.remove(j)\n",
        "\n",
        "sorted_keywords = sorted(keywords, key=lambda x: int(x[\"head\"]))\n",
        "print(sorted_keywords)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQDUPqczEEKf",
        "outputId": "790d66ac-6c42-4bc3-9928-0601d2ff4cef"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'content': '達賴喇嘛', 'type': 'PERSON', 'head': 431} {'content': '喇嘛', 'type': 'Na', 'head': 433}\n",
            "[{'content': '拜登', 'type': 'PERSON', 'head': 0}, {'content': '習近平將', 'type': 'PERSON', 'head': 3}, {'content': '舊金山', 'type': 'GPE', 'head': 8}, {'content': '核戰爭', 'type': 'Na', 'head': 20}, {'content': '人工智慧', 'type': 'Na', 'head': 24}, {'content': '機器', 'type': 'Na', 'head': 30}, {'content': '台灣', 'type': 'GPE', 'head': 33}, {'content': '問題', 'type': 'Na', 'head': 35}, {'content': '歷史性', 'type': 'Na', 'head': 42}, {'content': '峰會', 'type': 'Na', 'head': 46}, {'content': '領導人', 'type': 'Na', 'head': 55}, {'content': '翻譯', 'type': 'Na', 'head': 72}, {'content': 'Zoom', 'type': 'PERSON', 'head': 75}, {'content': '拜登', 'type': 'PERSON', 'head': 80}, {'content': '中國', 'type': 'GPE', 'head': 92}, {'content': '美國', 'type': 'GPE', 'head': 99}, {'content': '內政', 'type': 'Na', 'head': 102}, {'content': '俄羅斯', 'type': 'GPE', 'head': 109}, {'content': '哈馬斯', 'type': 'GPE', 'head': 113}, {'content': '菲律賓', 'type': 'GPE', 'head': 117}, {'content': '習近平', 'type': 'PERSON', 'head': 121}, {'content': '拜登', 'type': 'PERSON', 'head': 131}, {'content': '美國', 'type': 'GPE', 'head': 134}, {'content': '中國', 'type': 'GPE', 'head': 141}, {'content': '內政', 'type': 'Na', 'head': 144}, {'content': '台灣', 'type': 'GPE', 'head': 151}, {'content': '維吾爾', 'type': 'GPE', 'head': 154}, {'content': '香港', 'type': 'GPE', 'head': 158}, {'content': '領導人', 'type': 'Na', 'head': 163}, {'content': '底線', 'type': 'Na', 'head': 171}, {'content': '利益', 'type': 'Na', 'head': 180}, {'content': '貿易', 'type': 'Na', 'head': 187}, {'content': '疫情', 'type': 'Na', 'head': 192}, {'content': '芬太尼', 'type': 'Na', 'head': 197}, {'content': '成果', 'type': 'Na', 'head': 206}, {'content': '軍事', 'type': 'Na', 'head': 220}, {'content': '軍', 'type': 'Na', 'head': 227}, {'content': '飛機艦艇', 'type': 'Na', 'head': 239}, {'content': '艱難任務', 'type': 'VH+Na', 'head': 252}, {'content': '必要步驟', 'type': 'VH+Na', 'head': 263}, {'content': '危險地方', 'type': 'VH+Na', 'head': 288}, {'content': '問題', 'type': 'Na', 'head': 317}, {'content': '空間', 'type': 'Na', 'head': 327}, {'content': '空洞禮節性活動', 'type': 'VH+Na', 'head': 365}, {'content': '對話', 'type': 'Na', 'head': 381}, {'content': '中', 'type': 'GPE', 'head': 387}, {'content': '美', 'type': 'GPE', 'head': 388}, {'content': '關係', 'type': 'Na', 'head': 389}, {'content': '大期望', 'type': 'VH+Na', 'head': 408}, {'content': '拜登', 'type': 'PERSON', 'head': 417}, {'content': '習近平', 'type': 'PERSON', 'head': 420}, {'content': '奧巴馬', 'type': 'PERSON', 'head': 427}, {'content': '達賴喇嘛', 'type': 'PERSON', 'head': 431}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = [\"我們只能祈禱\"]\n",
        "word_seg = ws(text) #斷句\n",
        "print(word_seg)\n",
        "pos_result = pos(word_seg)\n",
        "print(pos_result)\n",
        "ner_result = ner(word_seg, pos_result)\n",
        "print(ner_result)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "awuaQM5uXIkd",
        "outputId": "efad6277-63ee-49fe-e960-c39dcb8f4a87"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['我們', '只', '能', '祈禱']]\n",
            "[['Nh', 'Da', 'D', 'VE']]\n",
            "[set()]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(word_seg[0])):\n",
        "  print(word_seg[0][i], pos_result[0][i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S0pWiJYaZA3c",
        "outputId": "008a573c-2b7a-4eb7-c121-981b817f5ba7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "我們 Nh\n",
            "只 Da\n",
            "能 D\n",
            "祈禱 VE\n"
          ]
        }
      ]
    }
  ]
}